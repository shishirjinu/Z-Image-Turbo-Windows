# setup_and_run.ps1 - One click setup for Z-Image Turbo (GGUF) with minimal UI
# Place this file in ZImage-Windows and double-click start_zimage.bat to run.

Write-Host '=== Z-Image Turbo: One-Click (4/6/10GB) â€” Minimal UI ==='
Write-Host ''

# 0. Basic checks
if (!(Get-Command python -ErrorAction SilentlyContinue)) {
    Write-Host "ERROR: Python not found. Install Python 3.10+ from https://python.org and re-run."
    exit 1
}

function Download-FileWithProgress {
    param(
        [Parameter(Mandatory=$true)][string]$Url,
        [Parameter(Mandatory=$true)][string]$Destination,
        [Parameter(Mandatory=$true)][string]$Label
    )

    $dir = Split-Path -Parent $Destination
    if (!(Test-Path $dir)) { New-Item -ItemType Directory -Path $dir | Out-Null }

    $wc = New-Object System.Net.WebClient
    $wc.Proxy.Credentials = [System.Net.CredentialCache]::DefaultCredentials

    $completed = $false
    $lastPercent = -1
    $wc.DownloadProgressChanged += {
        param($sender, $e)
        if ($e.ProgressPercentage -ne $lastPercent) {
            $lastPercent = $e.ProgressPercentage
            Write-Progress -Activity $Label -Status ("{0}% ({1} MB / {2} MB)" -f $e.ProgressPercentage, [math]::Round($e.BytesReceived/1MB,2), [math]::Round($e.TotalBytesToReceive/1MB,2)) -PercentComplete $e.ProgressPercentage
        }
    }
    $wc.DownloadFileCompleted += {
        $script:completed = $true
        Write-Progress -Activity $Label -Completed
    }

    $script:completed = $false
    $wc.DownloadFileAsync($Url, $Destination)
    while (-not $script:completed) {
        Start-Sleep -Milliseconds 200
    }
}

# 1. Create folders
$root = $PSScriptRoot
$sdBin = Join-Path $root "sd_bin"
$modelsDir = Join-Path $root "models"
$zimageDir = Join-Path $modelsDir "zimage"
$vaeDir = Join-Path $modelsDir "vae"
$llmDir = Join-Path $modelsDir "llm"
if (!(Test-Path $sdBin)) { New-Item -ItemType Directory -Path $sdBin | Out-Null }
if (!(Test-Path $modelsDir)) { New-Item -ItemType Directory -Path $modelsDir | Out-Null }
if (!(Test-Path $zimageDir)) { New-Item -ItemType Directory -Path $zimageDir | Out-Null }
if (!(Test-Path $vaeDir)) { New-Item -ItemType Directory -Path $vaeDir | Out-Null }
if (!(Test-Path $llmDir)) { New-Item -ItemType Directory -Path $llmDir | Out-Null }

Write-Host 'Folders prepared:'
Write-Host (" - sd_bin  : {0}" -f $sdBin)
Write-Host (" - models/zimage  : {0}" -f $zimageDir)
Write-Host (" - models/vae  : {0}" -f $vaeDir)
Write-Host (" - models/llm  : {0}" -f $llmDir)
Write-Host ''

# 2. Ask user about VRAM tier
Write-Host 'Choose your GPU VRAM tier (pick the number):'
Write-Host ' 1) 4 GB  (Fastest, smallest model, recommended for RTX 3050 4GB)'
Write-Host ' 2) 6-8 GB  (Better quality)'
Write-Host ' 3) 10+ GB  (Highest quality - not recommended for 4GB)'
$choice = Read-Host 'Enter 1, 2 or 3'

switch ($choice) {
    "1" {
        $moshort = "4GB"
        $model_name = "z_image_turbo_Q4_0.gguf"
        # Example public URL placeholder - replace if you prefer another source.
        $model_url = "https://huggingface.co/leejet/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q4_0.gguf"
    }
    "2" {
        $moshort = "6-8GB"
        $model_name = "z_image_turbo_Q6_K.gguf"
        $model_url = "https://huggingface.co/leejet/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q6_K.gguf"
    }
    "3" {
        $moshort = "10+GB"
        $model_name = "z_image_turbo_Q8_0.gguf"
        $model_url = "https://huggingface.co/leejet/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q8_0.gguf"
    }
    default {
        Write-Host "Invalid choice. Exiting."
        exit 1
    }
}

Write-Host ''
Write-Host ("You picked: {0}" -f $moshort)
Write-Host ("Model will be saved as: {0}" -f $model_name)
Write-Host ''

# 3. Create venv (if missing)
$venv = Join-Path $root "venv"
if (!(Test-Path $venv)) {
    Write-Host "Creating Python virtual environment..."
    python -m venv venv
} else {
    Write-Host "Virtual environment already exists (venv/)."
}

# 4. Use venv python directly (avoids PowerShell execution policy issues with Activate.ps1)
$venvPython = Join-Path $venv "Scripts\python.exe"
if (!(Test-Path $venvPython)) {
    Write-Host "ERROR: venv python not found at: $venvPython"
    exit 1
}

# 5. Upgrade pip safely
Write-Host "Upgrading pip..."
& $venvPython -m pip install --upgrade pip

# 6. Install Python deps for minimal UI
Write-Host 'Installing Python requirements (gradio, requests)...'
& $venvPython -m pip install gradio requests tqdm

# 7. Check for sd binary
$sdexe = Join-Path $sdBin "sd.exe"
if (!(Test-Path $sdexe)) {
    Write-Host ""
    Write-Host "IMPORTANT: A stable-diffusion.cpp Windows binary (sd.exe) is REQUIRED to run the model."
    Write-Host "Please download a prebuilt Windows binary from the official stable-diffusion.cpp releases (or compile it) and place the file named 'sd.exe' into the folder:"
    Write-Host "    $sdBin"
    Write-Host ""
    Write-Host "Press Enter after you have placed sd.exe, or Ctrl+C to exit."
    Read-Host
}

if (!(Test-Path $sdexe)) {
    Write-Host "sd.exe still not found in $sdBin. Exiting."
    exit 1
}

# 7b. Sanity-check sd.exe (common crash is missing DLL / wrong build)
Write-Host "`nChecking sd.exe..."
try {
    & $sdexe --help | Out-Null
} catch {
    # swallow - we will check exit code below
}
if ($LASTEXITCODE -ne 0) {
    Write-Host ""
    Write-Host "ERROR: sd.exe failed to start (exit code: $LASTEXITCODE)."
    Write-Host "This usually means a missing dependency or wrong sd.exe build." 
    Write-Host "" 
    Write-Host "Please check:" 
    Write-Host " 1) You extracted the release ZIP and copied sd.exe AND any .dll files next to it into:"
    Write-Host "    $sdBin"
    Write-Host " 2) Microsoft Visual C++ Redistributable 2015-2022 (x64) is installed"
    Write-Host " 3) If you downloaded a CUDA build, your NVIDIA driver supports that CUDA version"
    Write-Host " 4) Try the CPU-only ZIP (sd-...-bin-win-x64.zip) to confirm it works on your PC"
    Write-Host ""
    Write-Host "Press Enter to exit."
    Read-Host
    exit 1
}

# 8. Download the chosen quantized GGUF model if it does not exist
$dest = Join-Path $zimageDir $model_name
if (Test-Path $dest) {
    Write-Host "Model already exists: $dest"
} else {
    Write-Host "`nDownloading quantized model (this can be several GB)."
    Write-Host "Source URL (if it fails, open link in browser and download manually):"
    Write-Host "  $model_url`n"
    try {
        Download-FileWithProgress -Url $model_url -Destination $dest -Label ("Downloading Z-Image model: {0}" -f $model_name)
        Write-Host "Downloaded model to: $dest"
    } catch {
        Write-Host "Automatic download failed. Please download the file manually and place it into:"
        Write-Host "   $dest"
        Write-Host "Then press Enter to continue."
        Read-Host
        if (!(Test-Path $dest)) {
            Write-Host "Model not found. Exiting."
            exit 1
        }
    }
}

# 9. Download VAE + LLM (required by Z-Image pipeline)
$vaeName = "ae.safetensors"
$vaeUrl = "https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.safetensors"
$vaePath = Join-Path $vaeDir $vaeName

$llmName = "Qwen3-4B-Instruct-2507-Q4_K_M.gguf"
$llmUrl = "https://huggingface.co/unsloth/Qwen3-4B-Instruct-2507-GGUF/resolve/main/Qwen3-4B-Instruct-2507-Q4_K_M.gguf"
$llmPath = Join-Path $llmDir $llmName

if (Test-Path $vaePath) {
    Write-Host "VAE already exists: $vaePath"
} else {
    Write-Host "`nVAE is required but may be restricted for non-logged-in downloads on Hugging Face."
    Write-Host "Please download it manually (login may be required):"
    Write-Host "  $vaeUrl"
    Write-Host "Save it to:"
    Write-Host "  $vaePath"
    Write-Host "`nPress Enter after you have placed ae.safetensors, or Ctrl+C to exit."
    Read-Host
    if (!(Test-Path $vaePath)) {
        Write-Host "VAE not found. Exiting."
        exit 1
    }
}

if (Test-Path $llmPath) {
    Write-Host "LLM already exists: $llmPath"
} else {
    Write-Host "`nDownloading LLM (Qwen): $llmName"
    Write-Host "Source URL (if it fails, open link in browser and download manually):"
    Write-Host "  $llmUrl`n"
    try {
        Download-FileWithProgress -Url $llmUrl -Destination $llmPath -Label ("Downloading Qwen LLM: {0}" -f $llmName)
        Write-Host "Downloaded LLM to: $llmPath"
    } catch {
        Write-Host "Automatic download failed. Please download the file manually and place it into:"
        Write-Host "   $llmPath"
        Write-Host "Then press Enter to continue."
        Read-Host
        if (!(Test-Path $llmPath)) {
            Write-Host "LLM not found. Exiting."
            exit 1
        }
    }
}

# 10. (Re)create minimal Gradio UI script
$uiScript = Join-Path $root "run_gradio_ui.py"
Write-Host "Writing run_gradio_ui.py..."
$py = @'
import os, subprocess, shlex, uuid, time
import re
from pathlib import Path
import gradio as gr

ROOT = Path(__file__).parent
SD_EXE = str(ROOT / "sd_bin" / "sd.exe")
MODEL_PATH = str(ROOT / "models" / "zimage" / "__MODEL_NAME__")
OUTDIR = str(ROOT / "outputs")
os.makedirs(OUTDIR, exist_ok=True)

DEFAULT_VAE_PATH = str(ROOT / "models" / "vae" / "ae.safetensors")
DEFAULT_LLM_PATH = str(ROOT / "models" / "llm" / "Qwen3-4B-Instruct-2507-Q4_K_M.gguf")

FIRST_RUN = True

RES_PRESETS = [
    ("1:1 (256x256)", 256, 256),
    ("1:1 (512x512)", 512, 512),
    ("1:1 (768x768)", 768, 768),
    ("1:1 (1024x1024)", 1024, 1024),
    ("16:9 (640x384)", 640, 384),
    ("16:9 (896x512)", 896, 512),
    ("16:9 (1024x576)", 1024, 576),
    ("9:16 (384x640)", 384, 640),
    ("9:16 (512x896)", 512, 896),
    ("9:16 (576x1024)", 576, 1024),
    ("4:3 (640x480)", 640, 480),
    ("4:3 (768x576)", 768, 576),
    ("3:2 (768x512)", 768, 512),
    ("2:3 (512x768)", 512, 768),
]

SIZE_OPTIONS = sorted({s for _, w, h in RES_PRESETS for s in (w, h)})

def apply_preset(preset_label):
    for name, w, h in RES_PRESETS:
        if name == preset_label:
            return w, h
    return gr.update(), gr.update()

def gen_image(prompt, width, height, steps, seed, cfg_scale, vae_path, llm_path):
    uid = uuid.uuid4().hex[:8]
    out_file = os.path.join(OUTDIR, f"out_{uid}.png")
    if not os.path.isfile(SD_EXE):
        return None, f"sd.exe not found: {SD_EXE}"
    if not os.path.isfile(MODEL_PATH):
        return None, f"Model not found: {MODEL_PATH}"
    vae_path = (vae_path or "").strip() or DEFAULT_VAE_PATH
    llm_path = (llm_path or "").strip() or DEFAULT_LLM_PATH
    if not os.path.isfile(vae_path):
        return None, f"VAE not found: {vae_path}"
    if not os.path.isfile(llm_path):
        return None, f"LLM (text encoder) not found: {llm_path}"

    cmd = (
        f'"{SD_EXE}" '
        f'--diffusion-model "{MODEL_PATH}" '
        f'--vae "{vae_path}" '
        f'--llm "{llm_path}" '
        f'-p "{prompt}" '
        f'--cfg-scale {cfg_scale} '
        f'--steps {steps} '
        f'-H {height} -W {width} '
        f'-o "{out_file}" '
        f'--seed {seed}'
    )
    print("Running:", cmd)
    t0 = time.perf_counter()
    proc = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    t1 = time.perf_counter()
    elapsed = t1 - t0
    print(proc.stdout)
    reported = []
    if proc.stdout:
        m = re.search(r"generate_image completed in\s+([0-9.]+)s", proc.stdout)
        if m:
            reported.append(f"sd.exe generate_image: {m.group(1)}s")
        m = re.search(r"sampling completed, taking\s+([0-9.]+)s", proc.stdout)
        if m:
            reported.append(f"sd.exe sampling: {m.group(1)}s")
        m = re.search(r"loading tensors completed, taking\s+([0-9.]+)s", proc.stdout)
        if m:
            reported.append(f"sd.exe model load: {m.group(1)}s")

    timing_line = f"Wall-clock time: {elapsed:.2f}s"
    if reported:
        timing_line += "\n" + "\n".join(reported)

    combined_log = (timing_line + "\n\n" + (proc.stdout.strip() if proc.stdout else "")).strip()
    if proc.returncode != 0:
        return None, f"sd.exe exited with code {proc.returncode}\n\n{combined_log}".strip()
    imgs = sorted(Path(OUTDIR).glob("*.png"), key=lambda p: p.stat().st_mtime, reverse=True)
    if imgs:
        return str(imgs[0]), combined_log if combined_log else "Done"
    else:
        return None, (combined_log if combined_log else "No image was produced. Check sd.exe output above.")

with gr.Blocks() as demo:
    gr.Markdown("# Z-Image Turbo - Minimal UI")
    with gr.Tabs():
        with gr.Tab("Basic"):
            with gr.Row():
                prompt = gr.Textbox(label="Prompt", value="A large orange octopus on an ocean floor, cinematic, 8k")
            with gr.Row():
                preset = gr.Dropdown([n for n, _, _ in RES_PRESETS], value="1:1 (512x512)", label="Resolution / Aspect ratio")
            with gr.Row():
                width = gr.Dropdown(SIZE_OPTIONS, value=512, label="Width")
                height = gr.Dropdown(SIZE_OPTIONS, value=512, label="Height")
                steps = gr.Slider(1, 50, value=8, step=1, label="Steps")
            with gr.Row():
                cfg_scale = gr.Slider(0.0, 10.0, value=1.0, step=0.1, label="CFG Scale")
                seed = gr.Number(value=0, label="Seed (0 = random)")
            gr.Markdown("High resolutions (like 1024x1024) use more VRAM and take longer.")

        with gr.Tab("Advanced"):
            unlock = gr.Checkbox(value=False, label="Allow editing advanced paths")
            with gr.Row():
                vae_path = gr.Textbox(label="VAE path", value=DEFAULT_VAE_PATH, interactive=False)
                llm_path = gr.Textbox(label="LLM (Qwen) path", value=DEFAULT_LLM_PATH, interactive=False)

            def set_unlocked(enabled):
                return gr.update(interactive=bool(enabled)), gr.update(interactive=bool(enabled))

            unlock.change(set_unlocked, inputs=[unlock], outputs=[vae_path, llm_path])

    preset.change(apply_preset, inputs=[preset], outputs=[width, height])

    with gr.Row():
        btn = gr.Button("Generate")
    img = gr.Image(label="Result")
    status = gr.Textbox(label="Status", interactive=False, lines=12)

    def run_and_return(p, w, h, st, sd, cfg, vae, llm):
        global FIRST_RUN
        if FIRST_RUN:
            FIRST_RUN = False
            yield None, "Generating... (first run can take longer due to model loading)", gr.update(interactive=False)
        else:
            yield None, "Generating...", gr.update(interactive=False)
        out, log = gen_image(p, int(w), int(h), int(st), int(sd), float(cfg), vae, llm)
        if out:
            yield out, log if log else "Done", gr.update(interactive=True)
            return
        yield None, log if log else "Failed", gr.update(interactive=True)

    btn.click(run_and_return, inputs=[prompt, width, height, steps, seed, cfg_scale, vae_path, llm_path], outputs=[img, status, btn])

demo.launch(server_name="127.0.0.1", server_port=9000, share=False)
'@
$py = $py -replace '__MODEL_NAME__', $model_name
$py | Out-File -Encoding utf8 $uiScript
Write-Host "Wrote run_gradio_ui.py"

# 11. Run the UI
Write-Host "`nStarting the minimal UI (Gradio) at http://127.0.0.1:9000"
Write-Host "Press Ctrl+C in this window to stop."
& $venvPython (Join-Path $root "run_gradio_ui.py")
